{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as torch_optim\n",
    "from torchvision import models\n",
    "from torch.nn import init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import utility\n",
    "from utils.encoder import OneHotEncoder, ThermometerEncoder, IntegerEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from collections import OrderedDict\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TabularDataset(data.Dataset):\n",
    "    def __init__(self, df, encoders, features, is_clf):\n",
    "        assert encoders['ordinal'] != None and features['ordinal'] != None, \"need to pass ordinal encoders and features\"\n",
    "\n",
    "        self.data = {}\n",
    "        self.data['nominal'] = utility.concat(encoders['nominal'](df[features['nominal']])) if 'nominal' in encoders and 'nominal' in features else None\n",
    "        self.data['ordinal'] = utility.concat(encoders['ordinal'](df[features['ordinal']]))\n",
    "        self.data['continuous'] = df[features['continuous']].to_numpy() if 'continuous' in features else None\n",
    "        self.data['label'] = utility.concat(encoders['label'](df[features['label']])) if is_clf else df[features['label']].to_numpy()\n",
    "    def __len__(self):\n",
    "        return len(self.data['label'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {}\n",
    "        if not self.data['continuous'] is None:\n",
    "            item['continuous'] = self.data['continuous'][idx]\n",
    "        if not self.data['nominal'] is None:\n",
    "            item['nominal'] = self.data['nominal'][idx] \n",
    "        item['ordinal'] = self.data['ordinal'][idx]\n",
    "        item['label'] = self.data['label'][idx]\n",
    "        return item\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenBlock(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(input_size, hidden_size)\n",
    "        torch.nn.init.kaiming_uniform_(self.fc.weight, mode='fan_in', nonlinearity='relu')\n",
    "        torch.nn.init.zeros_(self.fc.bias)\n",
    "        self.drop = nn.Dropout(p=dropout)\n",
    "        self.bn = nn.BatchNorm1d(hidden_size)\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.drop(x)\n",
    "        x = self.bn(x)\n",
    "        return x\n",
    "            \n",
    "            \n",
    "# class ResidualBlock(nn.Module):\n",
    "#     def __init__(self, dim_sizes, dropouts):\n",
    "#         super().__init__()\n",
    "#         self.hidden_blocks = nn.Sequential(OrderedDict([(f'hidden{i+1}', HiddenBlock(dim_sizes[i], dim_sizes[i+1], dropouts[i])) for i in range(len(dim_sizes)-1)]))\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.hidden_blocks(x) + x  \n",
    "    \n",
    "        \n",
    "        \n",
    "class TabNNmodel(nn.Module):\n",
    "    def __init__(self, n_ord, dim_sizes, n_nom=0, n_numerical=0, n_label=0, dropouts=None, class_ratios=None, is_integer_encoder=False):\n",
    "        super(TabNNmodel, self).__init__()\n",
    "        self.n_layer = len(dim_sizes)\n",
    "        self.n_ord = n_ord\n",
    "        self.n_num = n_numerical\n",
    "        self.n_nom = n_nom\n",
    "        self.is_integer_encoder = is_integer_encoder\n",
    "        dim_sizes = [n_ord + n_nom + n_numerical]+dim_sizes\n",
    "        if dropouts is None:\n",
    "            dropouts = [0]*(self.n_layer+1)\n",
    "        elif isinstance(dropouts, float):\n",
    "            dropouts = [dropouts]*(self.n_layer+1)\n",
    "        self.dropouts = dropouts\n",
    "        self.drop = nn.Dropout(p=dropouts[0])\n",
    "        \n",
    "        if is_integer_encoder:\n",
    "            self.bn_ie = nn.BatchNorm1d(n_ord)\n",
    "        if self.n_num>0:\n",
    "            self.bn = nn.BatchNorm1d(n_numerical)\n",
    "            \n",
    "        self.hidden_blocks = nn.Sequential(OrderedDict([(f'hidden{i+1}', HiddenBlock(dim_sizes[i], dim_sizes[i+1], self.dropouts[i+1])) for i in range(len(dim_sizes)-1)]))\n",
    "        \n",
    "        if n_label > 0:\n",
    "            if n_label <= 2: \n",
    "                self.fc_last = nn.Linear(dim_sizes[-1], 1) \n",
    "                if not class_ratios is None:\n",
    "                    assert len(class_ratios) == 2, \"class ratio should has length of 2\"\n",
    "                    positive_ratio = class_ratios[-1]\n",
    "                    bias = -torch.log(torch.tensor(1 / positive_ratio - 1))\n",
    "                    self.fc_last.bias.data.fill_(bias)\n",
    "                else : torch.nn.init.zeros_(self.fc_last.bias)\n",
    "            else :\n",
    "                self.fc_last = nn.Linear(dim_sizes[-1], n_label)\n",
    "                if not class_ratios is None:\n",
    "                    assert len(class_ratios) == n_label, \"class ratio should has length of n_label\"\n",
    "                    biases = [-torch.log(torch.tensor(1 / ratio - 1)) for ratio in class_ratios]\n",
    "                    self.fc_last.bias.data = torch.tensor(biases)\n",
    "                else : torch.nn.init.zeros_(self.fc_last.bias)\n",
    "            torch.nn.init.xavier_uniform_(self.fc_last.weight) \n",
    "        else: \n",
    "            self.fc_last = nn.Linear(dim_sizes[-1], 1)\n",
    "            torch.nn.init.uniform_(self.fc_last.weight) \n",
    "        self.n_label = n_label\n",
    "           \n",
    "    def forward(self, x_ord, x_nom, x_num=None):\n",
    "        if self.is_integer_encoder:\n",
    "            x_ord = self.bn_ie(x_ord.double())\n",
    "        x = torch.cat((x_ord, x_nom), 1) if x_nom is not None else x_ord\n",
    "        x = self.drop(x.double())\n",
    "        if self.n_num>0:\n",
    "            x_num = self.bn(x_num.double())\n",
    "            x = torch.cat((x, x_num), 1)\n",
    "        x = self.hidden_blocks(x)\n",
    "        x = self.fc_last(x)\n",
    "        if self.n_label > 0:\n",
    "            if self.n_label <= 2: \n",
    "                x = F.sigmoid(x)\n",
    "            else : x = F.softmax(x, dim=-1)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import os\n",
    "class Trainer:\n",
    "    def __init__(self, df, features_dic):\n",
    "        self.device = None\n",
    "        self.df = df\n",
    "        self.original_df = None\n",
    "        self.features_dic = features_dic\n",
    "        self.save_model = False\n",
    "        self.log = False\n",
    "        self.model_dir_path, self.model_name = None, None\n",
    "        self.train_idx, self.val_idx, self.test_idx = None, None, None\n",
    "        self.dim_sizes = None\n",
    "        self._set_features_and_encoders()\n",
    "\n",
    "    def _set_features_and_encoders(self):\n",
    "        assert 'label' in self.features_dic and 'ordinal' in self.features_dic\n",
    "        self.encoders = {}\n",
    "        self.features = {}\n",
    "        feat_list = []\n",
    "        if 'nominal' in self.features_dic:\n",
    "            self.encoders['nominal'] = OneHotEncoder(self.features_dic['nominal'])\n",
    "            self.features['nominal'] = list(self.features_dic['nominal'].keys())\n",
    "            feat_list += self.features['nominal']\n",
    "        if isinstance(self.features_dic['label'], dict):\n",
    "            if len(list(self.features_dic['label'].values())[0]) > 2: \n",
    "                self.encoders['label'] = OneHotEncoder(self.features_dic['label'])\n",
    "            else:  self.encoders['label'] = IntegerEncoder(self.features_dic['label'], is_label=True)\n",
    "            self.features['label'] = list(self.features_dic['label'].keys())\n",
    "            self.is_clf = True\n",
    "        else: \n",
    "            self.features['label'] = self.features_dic['label']\n",
    "            self.is_clf = False\n",
    "        self.features['ordinal'] = list(self.features_dic['ordinal'].keys())\n",
    "        feat_list += self.features['label'] + self.features['ordinal']\n",
    "        cont_feat = list(set(self.df.columns) - set(feat_list))\n",
    "        if len(cont_feat) > 0: \n",
    "            self.features['continuous'] = cont_feat\n",
    "\n",
    "    def _set_model(self, dim_sizes, dropouts, class_ratios):\n",
    "        assert 'ordinal' in self.encoders, 'encoder for ordinal features is undefined'\n",
    "        if self.encoders['ordinal'].__str__() == \"IntegerEncoder\":\n",
    "            n_ord = len(self.features['ordinal'])\n",
    "            is_integer_encoder = True\n",
    "        else: \n",
    "            n_ord = sum([len(val) for val in self.features_dic['ordinal'].values()])\n",
    "            is_integer_encoder = False\n",
    "        \n",
    "        if 'nominal' in self.encoders:\n",
    "            if self.encoders['nominal'].__str__() == \"IntegerEncoder\":\n",
    "                n_nom = len(self.features['nominal'])\n",
    "            else: n_nom = sum([len(val) for val in self.features_dic['nominal'].values()])\n",
    "        else: n_nom = 0\n",
    "        \n",
    "        self.n_label = sum([len(val) for val in self.features_dic['label'].values()]) if self.is_clf else 0\n",
    "        n_cont = len(self.features_dic['continuous']) if 'continuous' in self.features_dic else 0\n",
    "        \n",
    "        self.model = TabNNmodel(n_ord=n_ord, dim_sizes=dim_sizes, n_nom=n_nom, n_numerical=n_cont, n_label=self.n_label, dropouts=dropouts, class_ratios=class_ratios, is_integer_encoder=is_integer_encoder)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.double()\n",
    "          \n",
    "    def _set_data_loader(self, df, batch_size, shuffle, num_workers):\n",
    "        assert 'ordinal' in self.encoders, \"ordinal encoders undefined\"\n",
    "        dataset = TabularDataset(df, self.encoders, self.features, self.is_clf)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        return dataloader\n",
    "        \n",
    "    def _set_optimizer(self, lr):\n",
    "        self.optimizer = optim.Adam(\n",
    "            self.model.parameters(), \n",
    "            lr=lr, \n",
    "        )\n",
    "    def _set_loss(self):\n",
    "        if self.n_label == 2: \n",
    "            self.loss = nn.BCELoss()\n",
    "        elif self.n_label > 2: \n",
    "            self.loss = nn.CrossEntropyLoss()\n",
    "        else : self.loss = nn.MSELoss()\n",
    "                    \n",
    "\n",
    "    def set_train_idx(self, idx):\n",
    "        self.train_idx = idx\n",
    "    \n",
    "    def set_val_idx(self, idx):\n",
    "        self.val_idx = idx\n",
    "        \n",
    "    def set_model_dir(self, path):\n",
    "        assert os.path.exists(path), \"model dir path doesn't exist\"\n",
    "        self.model_dir_path = path\n",
    "    \n",
    "    def set_model_name(self, name):\n",
    "        self.model_name = name\n",
    "    \n",
    "    def set_ord_enc(self, ord_enc):\n",
    "        self.encoders['ordinal'] = ord_enc(self.features_dic['ordinal'], self.features_dic['step_sizes']) if 'step_sizes' in self.features_dic else ord_enc(self.features_dic['ordinal'])\n",
    "        \n",
    "    def set_log(self):\n",
    "        self.log = True\n",
    "    \n",
    "    def set_save_model(self):\n",
    "        self.save_model = True\n",
    "    \n",
    "    def set_device(self, device):\n",
    "        self.device = device \n",
    "    \n",
    "    def process_continuous_data(self, type):\n",
    "        assert not self.train_idx is None and not self.val_idx is None, \"train or val indices must be specified\"\n",
    "        assert type == 'continuous' or type == 'label', \"invalid type\"\n",
    "        if self.original_df is None:\n",
    "            self.original_df = self.df.copy()\n",
    "        pre_process = StandardScaler()\n",
    "        pre_process.fit(self.original_df.iloc[self.train_idx][self.features[type]].to_numpy())\n",
    "        df_scaled = pre_process.transform(self.original_df[self.features[type]].to_numpy())\n",
    "        self.df_scaled = df_scaled\n",
    "        df_scaled = pd.DataFrame(df_scaled, columns = self.features[type])\n",
    "        for col in self.features[type]:\n",
    "            self.df[col] = df_scaled[col]\n",
    "        return pre_process\n",
    "    \n",
    "    def update_best_model(self, op, cur_val):\n",
    "        if op(cur_val, self.best_val):\n",
    "            update = True\n",
    "            self.best_val = cur_val\n",
    "        else : update = False\n",
    "        if update and self.save_model:\n",
    "            name = f\"{self.model_name}.pth\" if self.log else f\"{wandb.run.name}.pth\"\n",
    "            path = os.path.join(self.model_dir_path, name)\n",
    "            torch.save(self.model.state_dict(), path)\n",
    "            print(f\"model: {name} is saved to path: {path}\")\n",
    "        return update\n",
    "    \n",
    "    def probability_to_prediction(self,  y_true, y_prob):\n",
    "        size = y_true.size()\n",
    "        if self.n_label == 2:\n",
    "            return y_true, torch.Tensor([1 if val >=0.5 else 0 for val in y_prob]).reshape(size).to(self.device)\n",
    "        elif self.n_label > 2:\n",
    "            y_pred = torch.Tensor([torch.argmax(prob) for prob in y_prob]).to(self.device)\n",
    "            y = torch.Tensor([torch.argmax(true) for true in y_true]).to(self.device)\n",
    "            return y, y_pred\n",
    "        else : return y_true, y_prob\n",
    "        \n",
    "    def accuracy(self, y_pred, y_true):\n",
    "        return torch.sum(y_pred == y_true)/y_true.size(dim=0)\n",
    "    \n",
    "    def make_class_ratios(self):\n",
    "        assert not self.train_idx is None and not self.val_idx is None, \"train or val indices must be specified\"\n",
    "        train_df = self.df.iloc[self.train_idx]\n",
    "        length = len(train_df)\n",
    "        return [len(train_df[train_df[self.features['label'][0]] == val])/length for val in self.features_dic['label'][self.features['label'][0]]]\n",
    "    \n",
    "    def train_epoch(self, train_dl):\n",
    "        losses = []\n",
    "        self.model.train()\n",
    "        for i, data_dic in enumerate(train_dl): \n",
    "            x_ord, y = data_dic['ordinal'], data_dic['label']\n",
    "            x_num = data_dic['continuous'] if 'continuous' in data_dic else None\n",
    "            x_nom = data_dic['nominal'] if 'nominal' in data_dic else None\n",
    "            \n",
    "            x_ord, y = x_ord.to(self.device), y.to(self.device)\n",
    "            if not x_num is None:\n",
    "                x_num = x_num.to(self.device)\n",
    "                x_nom = x_nom.to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            y_pred = self.model(x_ord, x_nom, x_num)\n",
    "            # y_pred, y = torch.squeeze(y_pred), torch.squeeze(y)\n",
    "            loss = self.loss(y_pred, y)\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        return losses\n",
    "    \n",
    "    def val_epoch(self, val_dl):\n",
    "        losses, accs = [], []\n",
    "        self.model.eval()\n",
    "        for i, data_dic in enumerate(val_dl): \n",
    "            x_ord, y = data_dic['ordinal'], data_dic['label']\n",
    "            x_num = data_dic['continuous'] if 'continuous' in data_dic else None\n",
    "            x_nom = data_dic['nominal'] if 'nominal' in data_dic else None\n",
    "            \n",
    "            x_ord, y = x_ord.to(self.device), y.to(self.device)\n",
    "            if not x_num is None:\n",
    "                x_num = x_num.to(self.device)\n",
    "                x_nom = x_nom.to(self.device)\n",
    "            \n",
    "            y_pred = self.model(x_ord, x_nom, x_num)\n",
    "            # y_pred, y = torch.squeeze(y_pred), torch.squeeze(y)\n",
    "            loss = self.loss(y_pred.detach(), y.detach())\n",
    "            if self.is_clf:  \n",
    "                y, y_pred = self.probability_to_prediction(y, y_pred)\n",
    "                acc = self.accuracy(y_pred, y)\n",
    "                accs.append(acc.item())\n",
    "            else:\n",
    "                mae = nn.L1Loss()\n",
    "                accs.append(mae(y_pred, y).item())\n",
    "            losses.append(loss.item())\n",
    "        return losses, accs \n",
    "    \n",
    "    def train(self, config):\n",
    "        assert not self.train_idx is None and not self.val_idx is None, \"train or val indices must be specified\"\n",
    "        class_ratios = self.make_class_ratios() if self.is_clf else None\n",
    "        self._set_model(config[\"dim_sizes\"], config[\"dropouts\"], class_ratios)\n",
    "        self.dim_sizes = config[\"dim_sizes\"]\n",
    "        self._set_optimizer(config[\"lr\"])\n",
    "        self._set_loss()\n",
    "        train_dl = self._set_data_loader(self.df.iloc[self.train_idx], config[\"batch_size\"], config[\"shuffle\"], config[\"num_workers\"])\n",
    "        val_dl = self._set_data_loader(self.df.iloc[self.val_idx], config[\"batch_size\"], config[\"shuffle\"], config[\"num_workers\"])\n",
    "        stop_criterion = config['early_stopping']\n",
    "        margin = config['margin']\n",
    "        patience_cur = 0\n",
    "        self.best_val, op = np.inf, lambda x, y: x < y - margin\n",
    "        if self.log:\n",
    "            wandb.watch(self.model, log='all', log_freq=config['batch_size']/10 if config['batch_size']/10 >= 1 else 1)\n",
    "        for epoch in range(1, config['epoch']+1):\n",
    "            train_losses = self.train_epoch(train_dl)\n",
    "            val_losses, accs = self.val_epoch(val_dl)\n",
    "            wandb_status = {\n",
    "                \"epoch\": epoch,\n",
    "                \"train_loss\": sum(train_losses)/len(train_losses),\n",
    "                \"val_loss\": sum(val_losses)/len(val_losses),\n",
    "                }\n",
    "            if self.is_clf:\n",
    "                wandb_status.update({\"accuracy\": sum(accs)/len(accs)})\n",
    "                print(\"[epoch: %3d/%3d] train loss: %3f, test loss: %3f, accuracy: %3f\" % (epoch, config['epoch'], wandb_status[\"train_loss\"], wandb_status[\"val_loss\"], wandb_status['accuracy']))\n",
    "            else : \n",
    "                wandb_status.update({\"mae\": sum(accs)/len(accs)})\n",
    "                print(\"[epoch: %3d/%3d] train loss: %3f, test loss: %3f, mae: %3f\" % (epoch, config['epoch'], wandb_status[\"train_loss\"], wandb_status[\"val_loss\"], wandb_status[\"mae\"]))\n",
    "            if self.log:\n",
    "                wandb.log(wandb_status)\n",
    "            if self.update_best_model(op, wandb_status[\"val_loss\"]):\n",
    "                patience_cur = 0\n",
    "            else: patience_cur += 1\n",
    "  \n",
    "            if patience_cur >= stop_criterion:\n",
    "                print(\"Training stopped by early stopping\")\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tester:\n",
    "    def __init__(self, df, features_dic):\n",
    "        self.device = None\n",
    "        self.df = df\n",
    "        self.original_df = None\n",
    "        self.features_dic = features_dic\n",
    "        self.model_path = None\n",
    "        self._set_features_and_encoders()\n",
    "\n",
    "    def _set_features_and_encoders(self):\n",
    "        assert 'label' in self.features_dic and 'ordinal' in self.features_dic\n",
    "        self.encoders = {}\n",
    "        self.features = {}\n",
    "        feat_list = []\n",
    "        if 'nominal' in self.features_dic:\n",
    "            self.encoders['nominal'] = OneHotEncoder(self.features_dic['nominal'])\n",
    "            self.features['nominal'] = list(self.features_dic['nominal'].keys())\n",
    "            feat_list += self.features['nominal']\n",
    "        if isinstance(self.features_dic['label'], dict):\n",
    "            if len(list(self.features_dic['label'].values())[0]) > 2: \n",
    "                self.encoders['label'] = OneHotEncoder(self.features_dic['label'])\n",
    "            else:  self.encoders['label'] = IntegerEncoder(self.features_dic['label'], is_label=True)\n",
    "            self.features['label'] = list(self.features_dic['label'].keys())\n",
    "            self.is_clf = True\n",
    "        else: \n",
    "            self.features['label'] = self.features_dic['label']\n",
    "            self.is_clf = False\n",
    "        self.features['ordinal'] = list(self.features_dic['ordinal'].keys())\n",
    "        feat_list += self.features['label'] + self.features['ordinal']\n",
    "        cont_feat = list(set(self.df.columns) - set(feat_list))\n",
    "        if len(cont_feat) > 0:\n",
    "            self.features['continuous'] = cont_feat\n",
    "    \n",
    "    def _set_model(self, dim_sizes):\n",
    "        assert not self.model_path is None, \"model path must be specified\"\n",
    "        assert 'ordinal' in self.encoders, 'encoder for ordinal features is undefined'\n",
    "        if self.encoders['ordinal'].__str__() == \"IntegerEncoder\":\n",
    "            n_ord = len(self.features['ordinal'])\n",
    "            is_integer_encoder = True\n",
    "        else: \n",
    "            n_ord = sum([len(val) for val in self.features_dic['ordinal'].values()])\n",
    "            is_integer_encoder = False\n",
    "        \n",
    "        if 'nominal' in self.encoders:\n",
    "            if self.encoders['nominal'].__str__() == \"IntegerEncoder\":\n",
    "                n_nom = len(self.features['nominal'])\n",
    "            else: n_nom = sum([len(val) for val in self.features_dic['nominal'].values()])\n",
    "        else: n_nom = 0\n",
    "        \n",
    "        self.n_label = sum([len(val) for val in self.features_dic['label'].values()]) if self.is_clf else 0\n",
    "        n_cont = len(self.features_dic['continuous']) if 'continuous' in self.features_dic else 0\n",
    "        \n",
    "        self.model = TabNNmodel(n_ord=n_ord, dim_sizes=dim_sizes, n_nom=n_nom, n_numerical=n_cont, n_label=self.n_label, is_integer_encoder=is_integer_encoder)\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.load_state_dict(torch.load(self.model_path))\n",
    "        self.model.double()\n",
    "        \n",
    "\n",
    "    def _set_data_loader(self, df, batch_size, shuffle, num_workers):\n",
    "        assert 'ordinal' in self.encoders, \"ordinal encoders undefined\"\n",
    "        dataset = TabularDataset(df, self.encoders, self.features, self.is_clf)\n",
    "        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n",
    "        return dataloader\n",
    "            \n",
    "    def _set_eval_metric(self):\n",
    "        if self.is_clf:\n",
    "            self.eval_metric = {'clf_rep': lambda y_true, y_pred: classification_report(y_true, y_pred, output_dict=True)}\n",
    "        else : self.eval_metric = {\n",
    "                            'RMSE': lambda x,y : mean_squared_error(x, y, squared=False), \n",
    "                            'MAE': mean_absolute_error\n",
    "                            }\n",
    "    def set_ord_enc(self, ord_enc):\n",
    "        self.encoders['ordinal'] = ord_enc(self.features_dic['ordinal'], self.features_dic['step_sizes']) if 'step_sizes' in self.features_dic else ord_enc(self.features_dic['ordinal'])\n",
    "    \n",
    "    def set_model_path(self, path):\n",
    "        assert os.path.exists(path), \"path does not exist\"\n",
    "        self.model_path = path\n",
    "            \n",
    "    def set_device(self, device):\n",
    "        self.device = device\n",
    "            \n",
    "    def process_continuous_data(self, pre_process, type):\n",
    "        assert type == 'continuous' or type == 'label', \"invalid type\"\n",
    "        if self.original_df is None:\n",
    "            self.original_df = self.df.copy()\n",
    "        df_scaled = pre_process.transform(self.original_df[self.features[type]].to_numpy())\n",
    "        df_scaled = pd.DataFrame(df_scaled, columns = self.features[type])\n",
    "        for col in self.features[type]:\n",
    "            self.df[col] = df_scaled[col]\n",
    "            \n",
    "    def probability_to_prediction(self, y_true, y_prob):\n",
    "        shape = y_true.shape\n",
    "        if self.n_label == 2:\n",
    "            return y_true, np.array([1 if val >=0.5 else 0 for val in y_prob]).reshape(shape)\n",
    "        elif self.n_label > 2:\n",
    "            y_pred = np.array([np.argmax(prob) for prob in y_prob])\n",
    "            y = np.array([np.argmax(true) for true in y_true])\n",
    "            return y, y_pred\n",
    "        else : return y_true, y_prob\n",
    "            \n",
    "    def evaluate(self, y_true, y_pred):\n",
    "        loss_dic = {}\n",
    "        if self.device.type == 'cuda':\n",
    "            y_true, y_pred = y_true.to(torch.device('cpu')), y_pred.to(torch.device('cpu'))\n",
    "        y_true, y_pred = y_true.detach().numpy(), y_pred.detach().numpy()  \n",
    "        if self.is_clf:  \n",
    "            y_true, y_pred = self.probability_to_prediction(y_true, y_pred)\n",
    "        for k, metric in self.eval_metric.items():\n",
    "            loss_dic[k] = metric(y_true, y_pred)\n",
    "        return loss_dic\n",
    "\n",
    "    def test(self, config):\n",
    "        self._set_model(config[\"dim_sizes\"])\n",
    "        self._set_eval_metric()\n",
    "        if config['batch_size'] == 'all':\n",
    "            batch_size = len(self.df)\n",
    "        else: batch_size = config['batch_size']\n",
    "        test_dl = self._set_data_loader(self.df, batch_size, config[\"shuffle\"], config[\"num_workers\"])\n",
    "        self.model.eval()\n",
    "        result = {k: [] for k in self.eval_metric.keys()}\n",
    "        for data_dic in test_dl: \n",
    "            x_ord, y = data_dic['ordinal'], data_dic['label']\n",
    "            x_num = data_dic['continuous'] if 'continuous' in data_dic else None\n",
    "            x_nom = data_dic['nominal'] if 'nominal' in data_dic else None\n",
    "            \n",
    "            x_ord, y = x_ord.to(self.device), y.to(self.device)\n",
    "            if not x_num is None:\n",
    "                x_num = x_num.to(self.device)\n",
    "                x_nom = x_nom.to(self.device)\n",
    "            \n",
    "            y_pred = self.model(x_ord, x_nom, x_num)\n",
    "            \n",
    "            batch_eval = self.evaluate(y, y_pred)\n",
    "            for k, v in batch_eval.items():\n",
    "                result[k].append(v)\n",
    "        if self.is_clf:\n",
    "            for k in self.eval_metric.keys():\n",
    "                result[k] = utility.concat_dic(*result[k])\n",
    "                result[k] = utility.mean_std_dic(result[k], only_mean=True)\n",
    "        else:\n",
    "            result = {k: sum(v)/len(v) for k, v in result.items()}        \n",
    "        return result\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "import glob\n",
    "def open_dataset(path, data_name, dic_name):\n",
    "    data_path = os.path.join(path, data_name+\".csv\")\n",
    "    dic_path = os.path.join(path, dic_name+\"_dic.pkl\")\n",
    "    df = pd.read_csv(data_path)\n",
    "    with open(dic_path, 'rb') as f:\n",
    "        feature_dic = pickle.load(f)\n",
    "    return df, feature_dic\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')\n",
    "\n",
    "def get_encoders(encoder_name):\n",
    "    encoder_dic = {\n",
    "        'o': OneHotEncoder, 'ohe': OneHotEncoder, 'onehotencoder': OneHotEncoder,\n",
    "        't': ThermometerEncoder, 'te': ThermometerEncoder, 'thermometerencoder': ThermometerEncoder,\n",
    "        'i': IntegerEncoder, 'ie': IntegerEncoder, 'integerencoder': IntegerEncoder,\n",
    "    }\n",
    "    encoders = []\n",
    "    if isinstance(encoder_name, str):\n",
    "        if encoder_name == 'all':\n",
    "            return [OneHotEncoder, ThermometerEncoder, IntegerEncoder]\n",
    "        else : \n",
    "            encoders.append(encoder_dic[encoder_name.lower()])\n",
    "            return encoders\n",
    "    else:    \n",
    "        for name in encoder_name:\n",
    "            encoders.append(encoder_dic[name.lower()])\n",
    "        return encoders\n",
    "    \n",
    "def sweep_train(trainer, config=None):\n",
    "            with wandb.init(config=config):\n",
    "                config = wandb.config\n",
    "                trainer.train(config)\n",
    "                \n",
    "\n",
    "def train_log(trainer, mode, config, entity=None, project=None, group=None, name=None, count=None):\n",
    "    if mode == \"sweep\":\n",
    "        trainer.set_log()\n",
    "        sweep_id = wandb.sweep(config, entity=entity, project=project)\n",
    "        wandb.agent(sweep_id, function= lambda cfg=None: sweep_train(trainer=trainer, config=cfg), count=count)\n",
    "        os.system(f\"wandb sweep --stop {sweep_id}\")\n",
    "    elif mode == \"log\": \n",
    "        trainer.set_log()\n",
    "        with wandb.init(entity=entity, project=project, group=group, name=name, config=config):\n",
    "            config = wandb.config\n",
    "            trainer.train(config['parameters'])\n",
    "            wandb.finish()\n",
    "    else: \n",
    "        trainer.train(config['parameters'])\n",
    "    \n",
    "def k_fold_validation(k, config, return_test_set=False, return_pre_process=False):\n",
    "    data_path = os.path.join(config[\"dataset\"][\"path\"], config[\"dataset\"][\"name\"])\n",
    "    df, features_dic = open_dataset(data_path, config[\"dataset\"][\"name\"], config[\"dataset\"][\"name\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    if isinstance(features_dic['label'], dict):\n",
    "        train_df, test_df = train_test_split(df, test_size=config['dataset']['split'], random_state=config['dataset']['seed'], stratify=df[features_dic['label'].keys()])\n",
    "        kf = StratifiedKFold(k) \n",
    "        split = kf.split(train_df,y=train_df[features_dic['label'].keys()])\n",
    "    else: \n",
    "        train_df, test_df = train_test_split(df, test_size=config['dataset']['split'], random_state=config['dataset']['seed'])\n",
    "        kf = KFold(k)\n",
    "        split = kf.split(train_df)\n",
    "\n",
    "    if config['dataset']['save_test']:\n",
    "        test_path = os.path.join(data_path, config[\"dataset\"][\"name\"] + \"_test.csv\")\n",
    "        test_df.reset_index(drop=True).to_csv(test_path, index=False)\n",
    "    \n",
    "    mode = config['wandb']['mode']\n",
    "    encoders = get_encoders(config['model']['encoder'])\n",
    "    project = config['wandb']['project'] if 'project' in config['wandb'] else None\n",
    "    count = config['wandb']['count'] if 'count' in config['wandb'] else None\n",
    "    entity = config['wandb']['entity'] if 'entity' in config['wandb'] else None\n",
    "    group = config['wandb']['group'] if 'group' in config['wandb'] else None\n",
    " \n",
    "    trainer = Trainer(train_df.reset_index(drop=True), features_dic)\n",
    "    \n",
    "    device = get_device()\n",
    "    trainer.set_device(device)\n",
    "    \n",
    "    save_path = config[\"model\"][\"path\"]\n",
    "    model_name = config[\"model\"][\"name\"]\n",
    "    save_model =  config[\"model\"]['save']\n",
    "    if save_model:\n",
    "        trainer.set_save_model()\n",
    "    trainer.set_model_dir(save_path)\n",
    "    \n",
    "\n",
    "    pre_processes = {'continuous': [], 'label': []}\n",
    "    for i, (train_idx, val_idx) in enumerate(split):\n",
    "        trainer.set_train_idx(train_idx), trainer.set_val_idx(val_idx)\n",
    "        # if 'continuous' in features_dic:\n",
    "        #     sc_cont = trainer.process_continuous_data('continuous')\n",
    "        #     pre_processes['continuous'].append(sc_cont)\n",
    "        if not trainer.is_clf:\n",
    "            sc_label = trainer.process_continuous_data('label')\n",
    "            pre_processes['label'].append(sc_label)\n",
    "        for encoder in encoders:\n",
    "            name = f\"{model_name}_{encoder.__str__().lower()}_{i}\"\n",
    "            trainer.set_model_name(name)\n",
    "            trainer.set_ord_enc(encoder), \n",
    "            train_log(trainer, mode=mode, config=config['train'], project=project, group=group, name=name, count=count, entity=entity)\n",
    "    \n",
    "    if config['dataset']['save_pre_process']:\n",
    "        for key in pre_processes.keys():\n",
    "            if len(pre_processes[key])>0:\n",
    "                for i, sc in enumerate(pre_processes[key]):\n",
    "                    sc_path = os.path.join(config['dataset']['pre_process_path'], config['dataset']['name'], f'pre_process_{key}_{i}.gz')\n",
    "                    joblib.dump(sc, sc_path)\n",
    "    \n",
    "    if return_test_set and return_pre_process:\n",
    "        return test_df, pre_processes\n",
    "    elif return_test_set:\n",
    "        return test_df\n",
    "    elif return_pre_process:\n",
    "        return pre_processes\n",
    "    else: return None\n",
    "\n",
    "def evaluate(config):\n",
    "    data_path = os.path.join(config[\"dataset\"][\"path\"], config[\"dataset\"][\"name\"])\n",
    "    df, features_dic = open_dataset(data_path, config[\"dataset\"][\"name\"]+'_test', config[\"dataset\"][\"name\"])\n",
    "    \n",
    "    tester = Tester(df.reset_index(drop=True), features_dic)\n",
    "    \n",
    "    encoders = get_encoders(config['model']['encoder'])\n",
    "    \n",
    "    device = get_device()\n",
    "    tester.set_device(device)\n",
    "\n",
    "    pre_processes_paths = []    \n",
    "    if not tester.is_clf:\n",
    "        pre_processes_paths = glob.glob(os.path.join(config['dataset']['pre_process_path'], config['dataset']['name'],'pre_process_label_?.gz'))\n",
    "        pre_processes_paths = [joblib.load(p) for p in pre_processes_paths]\n",
    "    \n",
    "    model_paths = glob.glob(os.path.join(config['model']['path'],config['model']['name']+'*'))\n",
    "    result = {enc.__str__(): [] for enc in encoders} \n",
    "    for i, p in enumerate(model_paths):\n",
    "        tester.set_model_path(p)\n",
    "        if len(pre_processes_paths) != 0:\n",
    "            tester.process_continuous_data(pre_processes_paths[i], 'label')\n",
    "        for encoder in encoders:\n",
    "            tester.set_ord_enc(encoder)\n",
    "            cur_res = tester.test(config['parameters'])\n",
    "            result[encoder.__str__()].append(cur_res)\n",
    "    \n",
    "    for k, v in result.items():\n",
    "        temp = utility.concat_dic(*v)\n",
    "        result[k] = utility.mean_std_dic(temp)\n",
    "    \n",
    "    return result, tester\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = 'acs_datasource'\n",
    "enc = 'ohe'\n",
    "model_name = \"ep500_nofirstdr05_bz500_dz3_lr00001\"\n",
    "model_path = f\"C:/bachelor thesis/model/log_model/{dataset_name}/{enc}\"\n",
    "# model_path = f\"C:/bachelor thesis/model/sweep_model/{dataset_name}/\"\n",
    "config = {\n",
    "    \"dataset\":{\n",
    "        \"path\": \"C:/bachelor thesis/clean_dataset\",\n",
    "        \"name\":dataset_name,\n",
    "        \"split\": 0.1,\n",
    "        \"seed\": 42,\n",
    "        \"save_test\": True,\n",
    "        \"save_pre_process\": False,\n",
    "        \"pre_process_path\": \"C:/bachelor thesis/pre_processes\"\n",
    "    },\n",
    "    \"model\":{\n",
    "        \"save\": True,\n",
    "        \"encoder\": enc,\n",
    "        \"path\": model_path,\n",
    "        \"name\": model_name\n",
    "    },\n",
    "\n",
    "    \"wandb\":{\n",
    "        \"mode\": 'log',\n",
    "        \"entity\": 'wmarcellius123',\n",
    "        \"api_key\": \"f7ebacb09ecdb2b3a190349435297de4c856cbc1\",\n",
    "        \"project\": \"Log_ac\", \n",
    "        \"group\": \"init\",\n",
    "        \"count\": 5\n",
    "    },\n",
    "    \"train\": {},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_config = {\n",
    "    \"dataset\":{\n",
    "        \"path\": \"C:/bachelor thesis/clean_dataset\",\n",
    "        \"name\":\"credit-g_csv\",\n",
    "        \"pre_process_path\": \"C:/bachelor thesis/pre_processes\"\n",
    "    },\n",
    "    \"model\":{\n",
    "        \"path\": model_path,\n",
    "        \"encoder\":enc,\n",
    "        \"name\": model_name\n",
    "    },\n",
    "    \"parameters\": {\n",
    "        \"dim_sizes\": [360, 270,180,90],\n",
    "        \"batch_size\": 'all',\n",
    "        \"shuffle\": True,\n",
    "        \"num_workers\": 0\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "log_config = {\n",
    "    \"parameters\":{\n",
    "            \"epoch\": 500,\n",
    "            \"early_stopping\": 500,\n",
    "            \"margin\": 0.000001,\n",
    "            \"dim_sizes\": [222, 148, 74],\n",
    "            \"dropouts\":[0.0]+[0.5]*3,\n",
    "            'lr': 0.00001,\n",
    "            \"batch_size\":500, \n",
    "            \"shuffle\": True,\n",
    "            \"num_workers\": 0, \n",
    "        },\n",
    "    }\n",
    "config['train'].update(log_config)\n",
    "config['wandb']['mode'] = 'log'\n",
    "\n",
    "test_config['dataset']['name'] = config['dataset']['name']\n",
    "test_config['dataset']['pre_process_path'] = config['dataset']['pre_process_path']\n",
    "test_config['model']['path'] = config['model']['path']\n",
    "test_config['model']['encoder'] = config['model']['encoder']\n",
    "test_config['model']['name'] = config['model']['name']\n",
    "test_config['parameters']['dim_sizes'] = log_config['parameters']['dim_sizes']\n",
    "# test_config['parameters']['batc_size'] = log_config['parameters']['batch_size']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": 'reg',\n",
    "    \"metric\": {\"goal\": \"minimize\",\n",
    "            \"name\": \"val_loss\"},\n",
    "    \"method\": 'random',\n",
    "    \"parameters\":{\n",
    "            \"epoch\": {'value': 100},\n",
    "            \"early_stopping\": {'value': 100},\n",
    "            \"margin\": {'value': 0.000001},\n",
    "            \"dim_sizes\":{'values': [[148, 74], [222, 148, 74], [296, 222, 148, 74], [370, 296, 222, 148, 74]]},\n",
    "            \"dropouts\":{'value': None},\n",
    "            \"lr\": {'values':[0.001, 0.0001, 0.00001, 0.000001]},\n",
    "            \"batch_size\":{'values': [5000, 2500, 1000, 500]}, \n",
    "            \"shuffle\": {'value': True},\n",
    "            \"num_workers\": {'value': 0}, \n",
    "        },\n",
    "    }\n",
    "config['train'].update(sweep_config)\n",
    "config['wandb']['mode'] = 'sweep'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'path': 'C:/bachelor thesis/clean_dataset',\n",
       "  'name': 'acs_datasource',\n",
       "  'split': 0.1,\n",
       "  'seed': 42,\n",
       "  'save_test': True,\n",
       "  'save_pre_process': False,\n",
       "  'pre_process_path': 'C:/bachelor thesis/pre_processes'},\n",
       " 'model': {'save': True,\n",
       "  'encoder': 'ohe',\n",
       "  'path': 'C:/bachelor thesis/model/log_model/acs_datasource/ohe',\n",
       "  'name': 'ep500_nofirstdr05_bz500_dz3_lr00001'},\n",
       " 'wandb': {'mode': 'log',\n",
       "  'entity': 'wmarcellius123',\n",
       "  'api_key': 'f7ebacb09ecdb2b3a190349435297de4c856cbc1',\n",
       "  'project': 'Log_ac',\n",
       "  'group': 'init',\n",
       "  'count': 5},\n",
       " 'train': {'parameters': {'epoch': 500,\n",
       "   'early_stopping': 500,\n",
       "   'margin': 1e-06,\n",
       "   'dim_sizes': [222, 148, 74],\n",
       "   'dropouts': [0.0, 0.5, 0.5, 0.5],\n",
       "   'lr': 1e-05,\n",
       "   'batch_size': 500,\n",
       "   'shuffle': True,\n",
       "   'num_workers': 0}}}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: C:\\Users\\wmarc\\.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_NOTEBOOK_NAME\"] = \"nn.ipynb\"\n",
    "wandb.login(key=config['wandb']['api_key'], relogin=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_validation(k=10, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for en in ['ohe', 'te', 'ie']:\n",
    "    config['model']['encoder'] = en\n",
    "    config['model']['path'] = f\"C:/bachelor thesis/model/log_model/{dataset_name}/{en}\"\n",
    "    k_fold_validation(k=10, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "res, tester = evaluate(test_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dataset': {'path': 'C:/bachelor thesis/clean_dataset',\n",
       "  'name': 'car_evaluation',\n",
       "  'pre_process_path': 'C:/bachelor thesis/pre_processes'},\n",
       " 'model': {'path': 'C:/bachelor thesis/model/log_model/car_evaluation/ohe/',\n",
       "  'encoder': 'ohe',\n",
       "  'name': 'nofirstdr03_bz100_dz4_lr001'},\n",
       " 'parameters': {'dim_sizes': [63, 42, 21],\n",
       "  'batch_size': 'all',\n",
       "  'shuffle': True,\n",
       "  'num_workers': 0}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_name = 'breast'\n",
    "# test_config['dataset']['name'] = dataset_name\n",
    "\n",
    "# test_config['parameters']['dim_sizes'] = [360,270,180,90]\n",
    "\n",
    "\n",
    "model_1 = 'ep500_nofirstdr05_bz500_dz3_lr00001'\n",
    "model_2 = 'ep500_nofirstdr03_bz500_dz3_lr00001'\n",
    "model_3 = 'ep500_nofirstdr03_bz500_dz3_lr00001'\n",
    "modelss = [model_1, model_2, model_3]\n",
    "# modelss = [model_name]*3\n",
    "# modelss = [\"nofirstdr03_bz50_dz3_lr00001\"]*3\n",
    "res_all = {}\n",
    "for en, model in zip( ['ohe','te','ie'], modelss):\n",
    "    test_config['model']['path']=f\"C:/bachelor thesis/model/log_model/{dataset_name}/{en}/\"\n",
    "    test_config['model']['encoder']=en\n",
    "    test_config['model']['name'] = model\n",
    "    res, tester = evaluate(test_config)\n",
    "    res_all.update(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'clf_rep'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m d \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m12\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m encoder \u001b[38;5;129;01min\u001b[39;00m res_all\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m---> 16\u001b[0m     res_all_copy[encoder][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf_rep\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m {key: res_all[encoder][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf_rep\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m res_all[encoder][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf_rep\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro avg\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()}\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# df_lists = [pd.DataFrame(res_all_copy[key.__str__()]['clf_rep']).rename_axis(key.__str__(), axis=\"columns\") for key in res_all_copy.keys()]\u001b[39;00m\n\u001b[0;32m     18\u001b[0m df_lists \u001b[38;5;241m=\u001b[39m [round_decimal_places(pd\u001b[38;5;241m.\u001b[39mDataFrame(res_all_copy[key\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m()][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclf_rep\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mrename_axis(key\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__str__\u001b[39m(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdrop(index\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupport\u001b[39m\u001b[38;5;124m'\u001b[39m), d) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m res_all_copy\u001b[38;5;241m.\u001b[39mkeys()]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'clf_rep'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def deep_copy(dic):\n",
    "    dic_res = {}\n",
    "    for key, val in dic.items():\n",
    "        dic_res[key] = deep_copy(val) if isinstance(val, dict) else val\n",
    "    return dic_res\n",
    "    \n",
    "def round_decimal_places(df, d):\n",
    "    dec = math.pow(10,d)\n",
    "    df_copy = df.copy()\n",
    "    df_copy = df_copy.map(lambda x: (math.ceil(x[0]*dec)/dec, math.ceil(x[1]*dec)/dec))\n",
    "    return df_copy\n",
    "res_all_copy = deep_copy(res_all)\n",
    "d = 12\n",
    "for encoder in res_all.keys():\n",
    "    res_all_copy[encoder]['clf_rep']['accuracy'] = {key: res_all[encoder]['clf_rep']['accuracy'] for key in res_all[encoder]['clf_rep']['macro avg'].keys()}\n",
    "# df_lists = [pd.DataFrame(res_all_copy[key.__str__()]['clf_rep']).rename_axis(key.__str__(), axis=\"columns\") for key in res_all_copy.keys()]\n",
    "df_lists = [round_decimal_places(pd.DataFrame(res_all_copy[key.__str__()]['clf_rep']).rename_axis(key.__str__(), axis=\"columns\").drop(index='support'), d) for key in res_all_copy.keys()]\n",
    "\n",
    "plot_dic = {}\n",
    "metrics = ['accuracy','macro avg', 'weighted avg']\n",
    "inner_metrics = ['precision', 'recall', 'f1-score']\n",
    "\n",
    "plot_dic = {}\n",
    "for key in metrics:\n",
    "    plot_dic[key] = {k: [] for k in inner_metrics}\n",
    "    for key2 in inner_metrics:\n",
    "        for dfs in df_lists:\n",
    "            df_dict = dfs.to_dict()\n",
    "            plot_dic[key][key2].append(list(df_dict[key][key2]))\n",
    "            \n",
    "            \n",
    "# models = [\"OneHotEncoder\", \"ThermometerEncoder\", \"IntegerEncoder\", \"IntegerEncoderSame\"]\n",
    "models = [\"OneHotEncoder\", \"ThermometerEncoder\", \"IntegerEncoder\"]\n",
    "# model_names = ['OHE', 'TE', 'IE', 'IE_same']\n",
    "model_names = ['OHE', 'TE', 'IE']\n",
    "# colors = ['r', 'b', 'g', 'y']\n",
    "colors = ['r', 'b', 'g']\n",
    "# x_axis_placement = np.array([-0.325, -0.125, 0.125, 0.325])\n",
    "x_axis_placement = np.array([-0.125, 0, 0.125])\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12.5,4))\n",
    "# fig.suptitle(f'dim_sizes : IE_same = {[168, 160, 44]} and IE = {[183,122,61]}')\n",
    "ax = ax.ravel()\n",
    "for i, (key, val) in enumerate(plot_dic.items()):\n",
    "    if key == 'accuracy':\n",
    "        accs = np.array(val['precision'])\n",
    "        ax[i].errorbar(range(len(accs)), accs[:,0], accs[:,1], alpha = 0.5, fmt='--', color = 'grey') \n",
    "        for j, (mean, std) in enumerate(accs):\n",
    "            (_,caps,_)= ax[i].errorbar(j, accs[:,0][j], accs[:,1][j], color = colors[j], alpha = 1, fmt='.', markersize=10, capsize = 5) \n",
    "            for cap in caps:\n",
    "                cap.set_markeredgewidth(1)\n",
    "    else:  \n",
    "        for j, (key2, val2) in enumerate(val.items()):\n",
    "            model = np.array(val2)    \n",
    "            x_axis=np.ones(len(model))*j\n",
    "            ax[i].errorbar(x_axis + x_axis_placement, model[:,0], model[:,1], alpha = 0.5, fmt='--', color = 'grey')\n",
    "            for k in range(len(x_axis)):\n",
    "                (_,caps,_)= ax[i].errorbar(j + x_axis_placement[k], model[:,0][k], model[:,1][k], label=model_names[k], color = colors[k], alpha = 1, fmt='.', markersize=10, capsize = 5) if j == 0 else ax[i].errorbar(j + x_axis_placement[k], model[:,0][k], model[:,1][k], color = colors[k], alpha = 1, fmt='.', markersize=10, capsize = 5) \n",
    "                for cap in caps:\n",
    "                    cap.set_markeredgewidth(1)\n",
    "for i, axe in enumerate(ax):\n",
    "    axe.set_title(metrics[i])\n",
    "    if metrics[i] == 'accuracy':\n",
    "        axe.set_xticks(range(len(models)), model_names)\n",
    "    else:\n",
    "        axe.set_xticks(range(len(inner_metrics)), inner_metrics)\n",
    "\n",
    "ax[1].legend()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'res_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m res_all[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOneHotEncoder\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'res_all' is not defined"
     ]
    }
   ],
   "source": [
    "res_all['OneHotEncoder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x2bd2436cf90>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "res_temp = res_all\n",
    "\n",
    "metrics = ['RMSE', 'MAE']\n",
    "            \n",
    "            \n",
    "models = [\"OneHotEncoder\", \"ThermometerEncoder\", \"IntegerEncoder\"]\n",
    "model_names = ['OHE', 'TE', 'IE']\n",
    "colors = ['r', 'b', 'g']\n",
    "fig, ax = plt.subplots(1, 2, figsize=(8,4))\n",
    "ax = ax.ravel()\n",
    "for i, metric in enumerate(metrics):\n",
    "            mean, std = [], []\n",
    "            for model in models:\n",
    "                mean.append(res_temp[model][metric][0]), std.append(res_temp[model][metric][1])\n",
    "            ax[i].errorbar(range(len(models)), mean, std, alpha = 0.5, fmt='--', color = 'grey')    \n",
    "            for j, model in enumerate(models):\n",
    "                (_,caps,_)= ax[i].errorbar(j, mean[j], std[j], color = colors[j], alpha = 1, fmt='.', markersize=10, capsize = 5)\n",
    "                for cap in caps:\n",
    "                    cap.set_markeredgewidth(1)\n",
    "for i, axe in enumerate(ax):\n",
    "    axe.set_title(metrics[i])\n",
    "    axe.set_xticks(range(len(models)), model_names)\n",
    "ax[1].legend()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'C:/bachelor thesis/{dataset_name}_result/nn_result/bz250_dz3_lr000001_res.csv','w') as f:\n",
    "    for df in df_lists:\n",
    "        f.write(f\"{df.columns.name}\\n\")\n",
    "        df.to_csv(f)\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(res_all).to_csv('acs_datasource_result/nn_result/bz500_dz3_lr001_res.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_class_ratios(df, features_dic, class_name):\n",
    "#     length = len(df)\n",
    "#     print(features_dic['label'][class_name])\n",
    "#     return [len(df[df['class'] == val])/length for val in features_dic['label'][class_name]]\n",
    "\n",
    "# datapath = os.path.join(config['dataset']['path'], config['dataset']['name'])\n",
    "# df, features_dic = open_dataset(datapath, config['dataset']['name'], config['dataset']['name'])\n",
    "# tr = Trainer(df, features_dic)\n",
    "# tr.set_ord_enc(get_encoders('ohe')[0])\n",
    "# tr.set_train_idx(list(range(0,500)))\n",
    "# tr.set_val_idx(list(range(500,900)))\n",
    "# tr._set_model([183,122,61], None, [0.7, 0.3])\n",
    "# tr.model.parameters\n",
    "# torch.sum(tr.model.hidden_blocks.hidden1.fc.weight)/(61*183)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['dataset']['name'] = dataset_name\n",
    "data_path = os.path.join(config[\"dataset\"][\"path\"], config[\"dataset\"][\"name\"])\n",
    "df, features_dic = open_dataset(data_path, config[\"dataset\"][\"name\"], config[\"dataset\"][\"name\"])\n",
    "# train_df, test_df = train_test_split(df, test_size=config['dataset']['split'], random_state=config['dataset']['seed'], stratify=df[features_dic['label'].keys()])\n",
    "\n",
    "# train_idx, val_idx = list(range(0,700)), list(range(700, 900))\n",
    "\n",
    "# mode = config['wandb']['mode']\n",
    "# encoders = get_encoders(config['model']['encoder'])\n",
    "# project = config['wandb']['project'] if 'project' in config['wandb'] else None\n",
    "# count = config['wandb']['count'] if 'count' in config['wandb'] else None\n",
    "# entity = config['wandb']['entity'] if 'entity' in config['wandb'] else None\n",
    "# trainer = Trainer(train_df.reset_index(drop=True), features_dic)\n",
    "# save_path = config[\"model\"][\"path\"]\n",
    "# model_name = config[\"model\"][\"name\"]\n",
    "# trainer.set_model_dir(save_path)\n",
    "# device = get_device()\n",
    "# trainer.set_device(device)\n",
    "# trainer.set_train_idx(train_idx), trainer.set_val_idx(val_idx)\n",
    "# # if 'continuous' in features_dic:\n",
    "# #     sc_cont = trainer.process_continuous_data('continuous')\n",
    "# if not trainer.is_clf:\n",
    "#     sc_label = trainer.process_continuous_data('label')\n",
    "# trainer.set_model_name(model_name+'_'+str(1))\n",
    "# trainer.set_ord_enc(encoders[0])\n",
    "# # train_log(trainer, mode=mode, config=config['train'], project=project, name=model_name, count=count, entity=entity)\n",
    "# dl = trainer._set_data_loader(trainer.df.iloc[trainer.train_idx], 5000, True, 0)\n",
    "# ne = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nominal': {'RAC1P': array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       "  'MAR': array([1., 2., 3., 4., 5.]),\n",
       "  'COW': array([1., 2., 3., 4., 5., 6., 7., 8.]),\n",
       "  'SEX': array([1., 2.])},\n",
       " 'ordinal': {'ENG': array([1., 2., 3., 4.]),\n",
       "  'WKHP': array([ 1, 11, 21, 31, 41, 51, 61, 71, 81, 91]),\n",
       "  'AGEP': array([ 0, 10, 20, 30, 40, 50, 60, 70, 80, 90]),\n",
       "  'SCHL': array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "         14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24.])},\n",
       " 'step_sizes': {'AGEP': (0, 99, 10), 'WKHP': (1, 99, 10)},\n",
       " 'label': ['PINCP']}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def k_fold_validation(k, config):\n",
    "#     data_path = os.path.join(config[\"dataset\"][\"path\"], config[\"dataset\"][\"name\"])\n",
    "#     df, features_dic = open_dataset(data_path, config[\"dataset\"][\"name\"])\n",
    "#     train_df, test_df = train_test_split(df, test_size=config['dataset']['split'], random_state=config['dataset']['seed'])\n",
    "\n",
    "#     mode = config['wandb']['mode']\n",
    "#     encoders = get_encoders(config['model']['encoder'])\n",
    "#     project = config['wandb']['project'] if 'project' in config['wandb'] else None\n",
    "#     project_name = config['wandb']['name'] if 'name' in config['wandb'] else None\n",
    "#     count = config['wandb']['count'] if 'count' in config['wandb'] else None\n",
    "#     entity = config['wandb']['entity'] if 'entity' in config['wandb'] else None\n",
    " \n",
    "#     trainer = Trainer(train_df.reset_index(drop=True), features_dic)\n",
    "#     tester = Tester(test_df.reset_index(drop=True), features_dic)\n",
    "    \n",
    "#     device = get_device()\n",
    "#     trainer.set_device(device), tester.set_device(device)\n",
    "    \n",
    "#     save_path = config[\"model\"][\"path\"]\n",
    "#     model_name = config[\"model\"][\"name\"]\n",
    "#     trainer.set_model_dir(save_path)\n",
    "    \n",
    "#     kf = KFold(k) \n",
    "#     result = {enc.__str__(): [] for enc in encoders} \n",
    "#     for i, (train_idx, val_idx) in enumerate(kf.split(train_df)):\n",
    "#         trainer.set_train_idx(train_idx), trainer.set_val_idx(val_idx)\n",
    "#         if 'continuous' in features_dic:\n",
    "#             sc_cont = trainer.process_continuous_data('continuous')\n",
    "#             tester.process_continuous_data(sc_cont, 'continuous')\n",
    "#         if not trainer.is_clf:\n",
    "#             sc_label = trainer.process_continuous_data('label')\n",
    "#             tester.process_continuous_data(sc_label, 'label')\n",
    "#         trainer.set_model_name(model_name+'_'+str(i))\n",
    "#         for encoder in encoders:\n",
    "#             trainer.set_ord_enc(encoder), tester.set_ord_enc(encoder)\n",
    "#             train_log(trainer, mode=mode, config=config['train'], project=project, name=project_name+'_'+str(i), count=count, entity=entity)\n",
    "#             tester.set_model_path(trainer.cur_model_path)\n",
    "#             config['test']['dim_sizes'] = trainer.dim_sizes\n",
    "#             cur_res = tester.test(config['test'])\n",
    "#             result[encoder.__str__()].append(cur_res)\n",
    "    \n",
    "    \n",
    "#     for k, v in result.items():\n",
    "#         temp = utility.concat_dic(*v)\n",
    "#         result[k] = utility.mean_std_dic(temp)\n",
    "        \n",
    "#     return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
